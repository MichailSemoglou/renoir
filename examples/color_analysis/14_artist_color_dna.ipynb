{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artist Similarity & Color DNA Embeddings\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Every artist has a unique visual signature—a **\"Color DNA\"** that defines their work. In this lesson, we'll create numerical fingerprints that capture each artist's color characteristics, then use these embeddings to:\n",
    "\n",
    "- **Discover** unexpected similarities between artists\n",
    "- **Visualize** the landscape of artistic styles\n",
    "- **Build** a recommendation system (\"If you like Monet, try...\")\n",
    "- **Trace** artistic influences through color\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Feature Engineering**: Creating rich color fingerprints for artists\n",
    "2. **Embedding Spaces**: Representing artists as vectors\n",
    "3. **Dimensionality Reduction**: Visualizing with t-SNE and UMAP\n",
    "4. **Similarity Search**: Finding related artists\n",
    "5. **Influence Analysis**: Tracing artistic connections\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "```\n",
    "Artist's Works → Color Features → Artist Embedding → Similarity Space\n",
    "     ↓                ↓                  ↓                 ↓\n",
    "  Images        Statistics          Vector            Visualization\n",
    "                                   (Color DNA)        & Recommendations\n",
    "```\n",
    "\n",
    "Let's decode the color DNA of the masters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/wd/j924f0991098_c_v3zcljb500000gn/T/ipykernel_6422/296350074.py\", line 24, in <module>\n",
      "    import umap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/__init__.py\", line 7, in <module>\n",
      "    from .parametric_umap import ParametricUMAP, load_ParametricUMAP\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/parametric_umap.py\", line 13, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 46, in <module>\n",
      "    from tensorflow.python import pywrap_tfe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/pywrap_tfe.py\", line 25, in <module>\n",
      "    from tensorflow.python._pywrap_tfe import *\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/wd/j924f0991098_c_v3zcljb500000gn/T/ipykernel_6422/296350074.py\", line 24, in <module>\n",
      "    import umap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/__init__.py\", line 7, in <module>\n",
      "    from .parametric_umap import ParametricUMAP, load_ParametricUMAP\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/parametric_umap.py\", line 13, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 49, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/wd/j924f0991098_c_v3zcljb500000gn/T/ipykernel_6422/296350074.py\", line 24, in <module>\n",
      "    import umap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/__init__.py\", line 7, in <module>\n",
      "    from .parametric_umap import ParametricUMAP, load_ParametricUMAP\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/parametric_umap.py\", line 13, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 11, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import distribute\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__.distribute import combinations\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.distribute.combinations import env # line: 456\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/combinations.py\", line 33, in <module>\n",
      "    from tensorflow.python.distribute import collective_all_reduce_strategy\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 25, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_ops as cross_device_ops_lib\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 28, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_utils\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/cross_device_utils.py\", line 22, in <module>\n",
      "    from tensorflow.python.distribute import values as value_lib\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/values.py\", line 23, in <module>\n",
      "    from tensorflow.python.distribute import distribute_lib\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 205, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/experimental/__init__.py\", line 98, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 34, in <module>\n",
      "    from tensorflow.python.data.ops import iterator_ops\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 45, in <module>\n",
      "    from tensorflow.python.training.saver import BaseSaverBuilder\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/training/saver.py\", line 50, in <module>\n",
      "    from tensorflow.python.training import py_checkpoint_reader\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 19, in <module>\n",
      "    from tensorflow.python.util._pywrap_checkpoint_reader import CheckpointReader\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "initialization of _pywrap_checkpoint_reader raised unreported exception",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[31mImportError\u001b[39m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mSystemError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# UMAP for better visualization (optional)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mumap\u001b[39;00m\n\u001b[32m     25\u001b[39m     UMAP_AVAILABLE = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUMAP available for visualization\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/__init__.py:7\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[32m      6\u001b[39m         simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mparametric_umap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParametricUMAP, load_ParametricUMAP\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m      9\u001b[39m     warn(\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTensorflow not installed; ParametricUMAP will be unavailable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m         category=\u001b[38;5;167;01mImportWarning\u001b[39;00m,\n\u001b[32m     12\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/parametric_umap.py:13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KDTree\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Used for tf.data.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     15\u001b[39m     warn(\n\u001b[32m     16\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"The umap.parametric_umap package requires Tensorflow > 2.0 to be installed.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    You can install Tensorflow at https://www.tensorflow.org/install\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/__init__.py:47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     45\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/combinations.py:33\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01msix\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py:25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/cross_device_ops.py:28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/cross_device_utils.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/values.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:205\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/__init__.py:21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/experimental/__init__.py:98\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/experimental/service/__init__.py:419\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33;03mThis module contains:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m \u001b[33;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils_exp\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_autograph\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debug_mode\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterator_ops\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nested_structure_coder\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrackable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m trackable\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSaverBuilder\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecation\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collections_abc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/training/saver.py:50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaved_model\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpywrap_saved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrackable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m trackable\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m py_checkpoint_reader\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_util\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saveable_object\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/training/py_checkpoint_reader.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors_impl\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_checkpoint_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckpointReader\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34merror_translator\u001b[39m(e):\n",
      "\u001b[31mSystemError\u001b[39m: initialization of _pywrap_checkpoint_reader raised unreported exception"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Renoir imports\n",
    "from renoir import ArtistAnalyzer\n",
    "from renoir.color import ColorExtractor, ColorAnalyzer, ColorVisualizer\n",
    "\n",
    "# ML imports\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "\n",
    "# UMAP for better visualization (optional)\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"UMAP available for visualization\")\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"UMAP not installed. Install with: pip install umap-learn\")\n",
    "    print(\"Will use t-SNE instead.\")\n",
    "\n",
    "# Initialize renoir components\n",
    "artist_analyzer = ArtistAnalyzer()\n",
    "color_extractor = ColorExtractor()\n",
    "color_analyzer = ColorAnalyzer()\n",
    "visualizer = ColorVisualizer()\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\nLoading WikiArt dataset...\")\n",
    "dataset = artist_analyzer._load_dataset()\n",
    "print(f\"Loaded {len(dataset)} artworks\")\n",
    "\n",
    "# Get artist names\n",
    "artist_names = dataset.features['artist'].names\n",
    "print(f\"Found {len(artist_names)} artists\")\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Color DNA\n",
    "\n",
    "An artist's \"Color DNA\" is a numerical fingerprint that captures their characteristic use of color. We'll create this by:\n",
    "\n",
    "1. Extracting color features from multiple works\n",
    "2. Aggregating statistics across their oeuvre\n",
    "3. Creating a fixed-size vector representation\n",
    "\n",
    "### What Makes a Good Color DNA?\n",
    "\n",
    "| Feature Category | What It Captures |\n",
    "|------------------|------------------|\n",
    "| **Palette Statistics** | Typical colors, saturation, brightness |\n",
    "| **Color Temperature** | Warm vs cool preference |\n",
    "| **Harmony Patterns** | Use of complementary, triadic, analogous |\n",
    "| **Diversity** | Range vs consistency of palette |\n",
    "| **Contrast** | Dynamic range in brightness/saturation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_artwork_features(image, n_colors=8):\n",
    "    \"\"\"\n",
    "    Extract comprehensive color features from a single artwork.\n",
    "    \n",
    "    Returns a dictionary of numerical features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        palette = color_extractor.extract_dominant_colors(image, n_colors=n_colors)\n",
    "        if not palette or len(palette) < 3:\n",
    "            return None\n",
    "        \n",
    "        stats = color_analyzer.analyze_palette_statistics(palette)\n",
    "        temp = color_analyzer.analyze_color_temperature_distribution(palette)\n",
    "        harmony = color_analyzer.analyze_color_harmony(palette)\n",
    "        \n",
    "        # HSV analysis\n",
    "        hsv_colors = [color_analyzer.rgb_to_hsv(c) for c in palette]\n",
    "        hues = [h[0] for h in hsv_colors]\n",
    "        sats = [h[1] for h in hsv_colors]\n",
    "        vals = [h[2] for h in hsv_colors]\n",
    "        \n",
    "        # RGB analysis\n",
    "        reds = [c[0] for c in palette]\n",
    "        greens = [c[1] for c in palette]\n",
    "        blues = [c[2] for c in palette]\n",
    "        \n",
    "        features = {\n",
    "            # Central tendencies\n",
    "            'mean_hue': stats['mean_hue'],\n",
    "            'mean_saturation': stats['mean_saturation'],\n",
    "            'mean_brightness': stats['mean_value'],\n",
    "            'mean_red': np.mean(reds),\n",
    "            'mean_green': np.mean(greens),\n",
    "            'mean_blue': np.mean(blues),\n",
    "            \n",
    "            # Variability\n",
    "            'std_hue': np.std(hues),\n",
    "            'std_saturation': np.std(sats),\n",
    "            'std_brightness': np.std(vals),\n",
    "            \n",
    "            # Temperature\n",
    "            'warm_ratio': temp['warm_percentage'] / 100,\n",
    "            'cool_ratio': temp['cool_percentage'] / 100,\n",
    "            'neutral_ratio': temp['neutral_percentage'] / 100,\n",
    "            \n",
    "            # Diversity and scores\n",
    "            'color_diversity': color_analyzer.calculate_color_diversity(palette),\n",
    "            'saturation_score': color_analyzer.calculate_saturation_score(palette),\n",
    "            'brightness_score': color_analyzer.calculate_brightness_score(palette),\n",
    "            \n",
    "            # Harmony\n",
    "            'harmony_score': harmony.get('harmony_score', 0),\n",
    "            'n_complementary': len(harmony.get('complementary_pairs', [])),\n",
    "            'n_triadic': len(harmony.get('triadic_sets', [])),\n",
    "            'n_analogous': len(harmony.get('analogous_groups', [])),\n",
    "            \n",
    "            # Contrast\n",
    "            'brightness_range': max(vals) - min(vals),\n",
    "            'saturation_range': max(sats) - min(sats),\n",
    "            \n",
    "            # Color dominance\n",
    "            'red_dominance': np.mean(reds) / (np.mean(reds) + np.mean(greens) + np.mean(blues) + 1e-6),\n",
    "            'green_dominance': np.mean(greens) / (np.mean(reds) + np.mean(greens) + np.mean(blues) + 1e-6),\n",
    "            'blue_dominance': np.mean(blues) / (np.mean(reds) + np.mean(greens) + np.mean(blues) + 1e-6),\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Test on a single artwork\n",
    "test_works = artist_analyzer.extract_artist_works('claude-monet', limit=1)\n",
    "if test_works:\n",
    "    features = extract_artwork_features(test_works[0]['image'])\n",
    "    print(f\"Extracted {len(features)} features from artwork\")\n",
    "    print(\"\\nSample features:\")\n",
    "    for k, v in list(features.items())[:8]:\n",
    "        print(f\"  {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building Artist Color DNA\n",
    "\n",
    "Now we'll aggregate features across multiple works by each artist to create their Color DNA fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artist_color_dna(dataset, artist_idx, artist_name, n_works=30, n_colors=8):\n",
    "    \"\"\"\n",
    "    Create a Color DNA embedding for an artist by aggregating features\n",
    "    across multiple works.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Aggregated features (means and stds across works)\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    # Collect features from artist's works\n",
    "    count = 0\n",
    "    for item in dataset:\n",
    "        if item['artist'] == artist_idx:\n",
    "            features = extract_artwork_features(item['image'], n_colors)\n",
    "            if features:\n",
    "                all_features.append(features)\n",
    "                count += 1\n",
    "            if count >= n_works:\n",
    "                break\n",
    "    \n",
    "    if len(all_features) < 5:  # Need minimum works\n",
    "        return None, 0\n",
    "    \n",
    "    # Aggregate: compute mean and std for each feature\n",
    "    df = pd.DataFrame(all_features)\n",
    "    \n",
    "    color_dna = {}\n",
    "    for col in df.columns:\n",
    "        color_dna[f'{col}_mean'] = df[col].mean()\n",
    "        color_dna[f'{col}_std'] = df[col].std()\n",
    "    \n",
    "    return color_dna, len(all_features)\n",
    "\n",
    "\n",
    "# Select artists to analyze (mix of movements and styles)\n",
    "ARTISTS_TO_ANALYZE = [\n",
    "    # Impressionists\n",
    "    'claude-monet', 'pierre-auguste-renoir', 'edgar-degas', 'camille-pissarro',\n",
    "    # Post-Impressionists\n",
    "    'vincent-van-gogh', 'paul-cezanne', 'paul-gauguin', 'georges-seurat',\n",
    "    # Expressionists\n",
    "    'edvard-munch', 'ernst-ludwig-kirchner', 'wassily-kandinsky', 'egon-schiele',\n",
    "    # Old Masters\n",
    "    'rembrandt', 'johannes-vermeer', 'caravaggio', 'peter-paul-rubens',\n",
    "    # Romantics\n",
    "    'j.m.w.-turner', 'caspar-david-friedrich', 'eugene-delacroix',\n",
    "    # Modern\n",
    "    'pablo-picasso', 'henri-matisse', 'marc-chagall', 'salvador-dali',\n",
    "    # Realists\n",
    "    'gustave-courbet', 'jean-francois-millet', 'winslow-homer',\n",
    "    # Others\n",
    "    'gustav-klimt', 'alphonse-mucha', 'edward-hopper', 'frida-kahlo',\n",
    "    'georgia-o-keeffe', 'jackson-pollock', 'mark-rothko', 'andy-warhol'\n",
    "]\n",
    "\n",
    "# Build artist name to index mapping\n",
    "artist_to_idx = {name.lower(): idx for idx, name in enumerate(artist_names)}\n",
    "\n",
    "print(f\"Analyzing {len(ARTISTS_TO_ANALYZE)} artists...\")\n",
    "print(\"This may take a few minutes.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Color DNA for each artist\n",
    "artist_dna = {}\n",
    "artist_work_counts = {}\n",
    "\n",
    "for artist_name in ARTISTS_TO_ANALYZE:\n",
    "    # Find artist index\n",
    "    artist_key = artist_name.lower().replace(' ', '-')\n",
    "    artist_idx = artist_to_idx.get(artist_key)\n",
    "    \n",
    "    if artist_idx is None:\n",
    "        # Try partial match\n",
    "        matches = [k for k in artist_to_idx.keys() if artist_key in k or k in artist_key]\n",
    "        if matches:\n",
    "            artist_key = matches[0]\n",
    "            artist_idx = artist_to_idx[artist_key]\n",
    "    \n",
    "    if artist_idx is None:\n",
    "        print(f\"  [!] Artist not found: {artist_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Create Color DNA\n",
    "    dna, n_works = create_artist_color_dna(dataset, artist_idx, artist_name, n_works=30)\n",
    "    \n",
    "    if dna:\n",
    "        # Store with readable name\n",
    "        display_name = artist_name.replace('-', ' ').title()\n",
    "        artist_dna[display_name] = dna\n",
    "        artist_work_counts[display_name] = n_works\n",
    "        print(f\"  [OK] {display_name}: {n_works} works analyzed\")\n",
    "    else:\n",
    "        print(f\"  [!] Insufficient works for: {artist_name}\")\n",
    "\n",
    "print(f\"\\nSuccessfully created Color DNA for {len(artist_dna)} artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and matrix\n",
    "dna_df = pd.DataFrame(artist_dna).T\n",
    "print(f\"Color DNA matrix shape: {dna_df.shape}\")\n",
    "print(f\"Features per artist: {dna_df.shape[1]}\")\n",
    "\n",
    "# Show sample of the data\n",
    "print(\"\\nSample Color DNA features (first 6 columns):\")\n",
    "print(dna_df.iloc[:5, :6].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Visualizing the Artist Landscape\n",
    "\n",
    "We'll use dimensionality reduction to visualize how artists relate to each other in color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "X = dna_df.values\n",
    "artist_list = list(dna_df.index)\n",
    "\n",
    "# Handle any NaN values\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Prepared {len(artist_list)} artists with {X_scaled.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization\n",
    "print(\"Computing t-SNE projection...\")\n",
    "tsne = TSNE(n_components=2, random_state=SEED, perplexity=min(10, len(artist_list)-1), \n",
    "            learning_rate='auto', init='pca')\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# UMAP visualization (if available)\n",
    "if UMAP_AVAILABLE:\n",
    "    print(\"Computing UMAP projection...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=SEED, n_neighbors=min(10, len(artist_list)-1))\n",
    "    X_umap = reducer.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Projections complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define artist movements/styles for coloring\n",
    "ARTIST_MOVEMENTS = {\n",
    "    'Claude Monet': 'Impressionism',\n",
    "    'Pierre Auguste Renoir': 'Impressionism',\n",
    "    'Edgar Degas': 'Impressionism',\n",
    "    'Camille Pissarro': 'Impressionism',\n",
    "    'Vincent Van Gogh': 'Post-Impressionism',\n",
    "    'Paul Cezanne': 'Post-Impressionism',\n",
    "    'Paul Gauguin': 'Post-Impressionism',\n",
    "    'Georges Seurat': 'Post-Impressionism',\n",
    "    'Edvard Munch': 'Expressionism',\n",
    "    'Ernst Ludwig Kirchner': 'Expressionism',\n",
    "    'Wassily Kandinsky': 'Expressionism',\n",
    "    'Egon Schiele': 'Expressionism',\n",
    "    'Rembrandt': 'Old Masters',\n",
    "    'Johannes Vermeer': 'Old Masters',\n",
    "    'Caravaggio': 'Old Masters',\n",
    "    'Peter Paul Rubens': 'Old Masters',\n",
    "    'J.M.W. Turner': 'Romanticism',\n",
    "    'Caspar David Friedrich': 'Romanticism',\n",
    "    'Eugene Delacroix': 'Romanticism',\n",
    "    'Pablo Picasso': 'Modern',\n",
    "    'Henri Matisse': 'Modern',\n",
    "    'Marc Chagall': 'Modern',\n",
    "    'Salvador Dali': 'Modern',\n",
    "    'Gustave Courbet': 'Realism',\n",
    "    'Jean Francois Millet': 'Realism',\n",
    "    'Winslow Homer': 'Realism',\n",
    "    'Gustav Klimt': 'Art Nouveau',\n",
    "    'Alphonse Mucha': 'Art Nouveau',\n",
    "    'Edward Hopper': 'American',\n",
    "    'Frida Kahlo': 'Modern',\n",
    "    'Georgia O Keeffe': 'American',\n",
    "    'Jackson Pollock': 'Abstract',\n",
    "    'Mark Rothko': 'Abstract',\n",
    "    'Andy Warhol': 'Pop Art'\n",
    "}\n",
    "\n",
    "MOVEMENT_COLORS = {\n",
    "    'Impressionism': '#74b9ff',\n",
    "    'Post-Impressionism': '#a29bfe',\n",
    "    'Expressionism': '#e74c3c',\n",
    "    'Old Masters': '#8e44ad',\n",
    "    'Romanticism': '#e67e22',\n",
    "    'Modern': '#27ae60',\n",
    "    'Realism': '#95a5a6',\n",
    "    'Art Nouveau': '#f39c12',\n",
    "    'American': '#1abc9c',\n",
    "    'Abstract': '#e84393',\n",
    "    'Pop Art': '#fd79a8'\n",
    "}\n",
    "\n",
    "# Get movement for each artist\n",
    "def get_movement(artist):\n",
    "    for key, movement in ARTIST_MOVEMENTS.items():\n",
    "        if key.lower() in artist.lower() or artist.lower() in key.lower():\n",
    "            return movement\n",
    "    return 'Other'\n",
    "\n",
    "movements = [get_movement(a) for a in artist_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2 if UMAP_AVAILABLE else 1, figsize=(18 if UMAP_AVAILABLE else 12, 10))\n",
    "if not UMAP_AVAILABLE:\n",
    "    axes = [axes]\n",
    "\n",
    "# t-SNE plot\n",
    "ax = axes[0]\n",
    "for movement in set(movements):\n",
    "    mask = [m == movement for m in movements]\n",
    "    color = MOVEMENT_COLORS.get(movement, '#95a5a6')\n",
    "    indices = [i for i, m in enumerate(mask) if m]\n",
    "    ax.scatter(X_tsne[indices, 0], X_tsne[indices, 1], \n",
    "              c=color, label=movement, s=150, alpha=0.7, edgecolors='white', linewidth=2)\n",
    "\n",
    "# Add artist labels\n",
    "for i, artist in enumerate(artist_list):\n",
    "    # Shorten long names\n",
    "    short_name = artist.split()[-1] if len(artist) > 15 else artist\n",
    "    ax.annotate(short_name, (X_tsne[i, 0], X_tsne[i, 1]), \n",
    "                fontsize=8, ha='center', va='bottom',\n",
    "                xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "ax.set_xlabel('t-SNE 1', fontsize=12)\n",
    "ax.set_ylabel('t-SNE 2', fontsize=12)\n",
    "ax.set_title('Artist Color DNA: t-SNE Visualization', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=9, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# UMAP plot (if available)\n",
    "if UMAP_AVAILABLE:\n",
    "    ax = axes[1]\n",
    "    for movement in set(movements):\n",
    "        mask = [m == movement for m in movements]\n",
    "        color = MOVEMENT_COLORS.get(movement, '#95a5a6')\n",
    "        indices = [i for i, m in enumerate(mask) if m]\n",
    "        ax.scatter(X_umap[indices, 0], X_umap[indices, 1], \n",
    "                  c=color, label=movement, s=150, alpha=0.7, edgecolors='white', linewidth=2)\n",
    "    \n",
    "    for i, artist in enumerate(artist_list):\n",
    "        short_name = artist.split()[-1] if len(artist) > 15 else artist\n",
    "        ax.annotate(short_name, (X_umap[i, 0], X_umap[i, 1]), \n",
    "                    fontsize=8, ha='center', va='bottom',\n",
    "                    xytext=(0, 5), textcoords='offset points')\n",
    "    \n",
    "    ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "    ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "    ax.set_title('Artist Color DNA: UMAP Visualization', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=9, ncol=2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Artist Similarity Analysis\n",
    "\n",
    "Let's compute and visualize pairwise similarities between artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrices\n",
    "cosine_sim = cosine_similarity(X_scaled)\n",
    "euclidean_dist = euclidean_distances(X_scaled)\n",
    "\n",
    "# Convert distance to similarity (inverted and normalized)\n",
    "euclidean_sim = 1 / (1 + euclidean_dist)\n",
    "\n",
    "# Create DataFrames\n",
    "cosine_df = pd.DataFrame(cosine_sim, index=artist_list, columns=artist_list)\n",
    "euclidean_df = pd.DataFrame(euclidean_sim, index=artist_list, columns=artist_list)\n",
    "\n",
    "print(\"Similarity matrices computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "# Cluster artists for better visualization\n",
    "from scipy.cluster.hierarchy import leaves_list\n",
    "linkage_matrix = linkage(X_scaled, method='ward')\n",
    "order = leaves_list(linkage_matrix)\n",
    "\n",
    "# Reorder similarity matrix\n",
    "ordered_artists = [artist_list[i] for i in order]\n",
    "ordered_sim = cosine_df.loc[ordered_artists, ordered_artists]\n",
    "\n",
    "# Plot heatmap\n",
    "mask = np.triu(np.ones_like(ordered_sim, dtype=bool), k=1)\n",
    "sns.heatmap(ordered_sim, mask=mask, cmap='RdYlBu_r', center=0.5,\n",
    "            square=True, linewidths=0.5, ax=ax,\n",
    "            cbar_kws={'shrink': 0.6, 'label': 'Cosine Similarity'},\n",
    "            annot=False)\n",
    "\n",
    "ax.set_title('Artist Color DNA Similarity Matrix\\n(Hierarchically Clustered)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering dendrogram\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    labels=artist_list,\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=10,\n",
    "    ax=ax,\n",
    "    color_threshold=0.7 * max(linkage_matrix[:, 2])\n",
    ")\n",
    "\n",
    "ax.set_title('Artist Color DNA: Hierarchical Clustering', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Artist', fontsize=12)\n",
    "ax.set_ylabel('Distance', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Artist Recommendation System\n",
    "\n",
    "Now let's build a recommendation system: \"If you like Artist X, you might also like...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def find_similar_artists(artist_name, similarity_df, top_n=5, exclude_self=True):\n    \"\"\"\n    Find the most similar artists to a given artist.\n    \n    Args:\n        artist_name: Name of the query artist\n        similarity_df: DataFrame of pairwise similarities\n        top_n: Number of recommendations\n        exclude_self: Whether to exclude the artist themselves\n        \n    Returns:\n        List of (artist_name, similarity_score) tuples\n    \"\"\"\n    # Find matching artist name in index\n    matches = [a for a in similarity_df.index if artist_name.lower() in a.lower()]\n    \n    if not matches:\n        print(f\"Artist '{artist_name}' not found in database.\")\n        return []\n    \n    artist = matches[0]\n    \n    # Get similarities\n    similarities = similarity_df.loc[artist].copy()\n    \n    if exclude_self:\n        similarities = similarities.drop(artist)\n    \n    # Sort and return top N\n    top_similar = similarities.sort_values(ascending=False).head(top_n)\n    \n    return list(top_similar.items())\n\n\ndef recommend_artists(artist_name, similarity_df, top_n=5):\n    \"\"\"\n    Generate artist recommendations with explanation.\n    \"\"\"\n    similar = find_similar_artists(artist_name, similarity_df, top_n)\n    \n    if not similar:\n        return\n    \n    print(f\"\\nIf you like {artist_name}, you might also enjoy:\")\n    print(\"=\" * 50)\n    \n    for i, (rec_artist, score) in enumerate(similar, 1):\n        movement = get_movement(rec_artist)\n        print(f\"  {i}. {rec_artist}\")\n        print(f\"     Movement: {movement}\")\n        print(f\"     Color similarity: {score:.1%}\")\n        print()\n\n\n# Test recommendations\ntest_artists = ['Monet', 'Van Gogh', 'Rembrandt', 'Picasso']\n\nfor artist in test_artists:\n    recommend_artists(artist, cosine_df, top_n=3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive recommendation explorer\n",
    "def visualize_recommendations(artist_name, similarity_df, X_2d, artist_list, top_n=5):\n",
    "    \"\"\"\n",
    "    Visualize an artist and their recommendations in 2D space.\n",
    "    \"\"\"\n",
    "    similar = find_similar_artists(artist_name, similarity_df, top_n)\n",
    "    \n",
    "    if not similar:\n",
    "        return\n",
    "    \n",
    "    # Find indices\n",
    "    query_matches = [i for i, a in enumerate(artist_list) if artist_name.lower() in a.lower()]\n",
    "    if not query_matches:\n",
    "        return\n",
    "    query_idx = query_matches[0]\n",
    "    \n",
    "    rec_indices = []\n",
    "    for rec_artist, _ in similar:\n",
    "        for i, a in enumerate(artist_list):\n",
    "            if rec_artist == a:\n",
    "                rec_indices.append(i)\n",
    "                break\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # All artists (gray)\n",
    "    ax.scatter(X_2d[:, 0], X_2d[:, 1], c='lightgray', s=80, alpha=0.5)\n",
    "    \n",
    "    # Query artist (large, red)\n",
    "    ax.scatter(X_2d[query_idx, 0], X_2d[query_idx, 1], \n",
    "              c='#e74c3c', s=300, edgecolors='black', linewidth=2, \n",
    "              label=f'Query: {artist_list[query_idx]}', zorder=5)\n",
    "    \n",
    "    # Recommendations (blue)\n",
    "    for i, (rec_idx, (rec_name, score)) in enumerate(zip(rec_indices, similar)):\n",
    "        ax.scatter(X_2d[rec_idx, 0], X_2d[rec_idx, 1],\n",
    "                  c='#3498db', s=200, edgecolors='black', linewidth=2, zorder=4)\n",
    "        # Draw line from query to recommendation\n",
    "        ax.plot([X_2d[query_idx, 0], X_2d[rec_idx, 0]], \n",
    "               [X_2d[query_idx, 1], X_2d[rec_idx, 1]],\n",
    "               'b--', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    # Labels for query and recommendations\n",
    "    ax.annotate(artist_list[query_idx], (X_2d[query_idx, 0], X_2d[query_idx, 1]),\n",
    "                fontsize=11, fontweight='bold', ha='center', va='bottom',\n",
    "                xytext=(0, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='#e74c3c', alpha=0.8),\n",
    "                color='white')\n",
    "    \n",
    "    for rec_idx, (rec_name, score) in zip(rec_indices, similar):\n",
    "        ax.annotate(f\"{rec_name}\\n({score:.0%})\", (X_2d[rec_idx, 0], X_2d[rec_idx, 1]),\n",
    "                    fontsize=9, ha='center', va='bottom',\n",
    "                    xytext=(0, 8), textcoords='offset points',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='#3498db', alpha=0.8),\n",
    "                    color='white')\n",
    "    \n",
    "    ax.set_title(f'Artist Recommendations for {artist_list[query_idx]}', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Dimension 1', fontsize=11)\n",
    "    ax.set_ylabel('Dimension 2', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize recommendations for a few artists\n",
    "visualize_recommendations('Monet', cosine_df, X_tsne, artist_list, top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More visualization examples\n",
    "visualize_recommendations('Van Gogh', cosine_df, X_tsne, artist_list, top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_recommendations('Rembrandt', cosine_df, X_tsne, artist_list, top_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Analyzing Artistic Influences\n",
    "\n",
    "Can we trace artistic influences through color similarity? Let's explore connections between movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute movement-level similarities\n",
    "def compute_movement_similarity(dna_df, artist_movements):\n",
    "    \"\"\"\n",
    "    Compute average Color DNA similarity between movements.\n",
    "    \"\"\"\n",
    "    # Group artists by movement\n",
    "    movement_dna = defaultdict(list)\n",
    "    \n",
    "    for artist in dna_df.index:\n",
    "        movement = get_movement(artist)\n",
    "        if movement != 'Other':\n",
    "            movement_dna[movement].append(dna_df.loc[artist].values)\n",
    "    \n",
    "    # Compute mean DNA per movement\n",
    "    movement_means = {}\n",
    "    for movement, dnas in movement_dna.items():\n",
    "        if dnas:\n",
    "            movement_means[movement] = np.mean(dnas, axis=0)\n",
    "    \n",
    "    # Compute pairwise similarities\n",
    "    movements = list(movement_means.keys())\n",
    "    n = len(movements)\n",
    "    sim_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            vec_i = movement_means[movements[i]].reshape(1, -1)\n",
    "            vec_j = movement_means[movements[j]].reshape(1, -1)\n",
    "            sim_matrix[i, j] = cosine_similarity(vec_i, vec_j)[0, 0]\n",
    "    \n",
    "    return pd.DataFrame(sim_matrix, index=movements, columns=movements)\n",
    "\n",
    "\n",
    "# Compute movement similarities\n",
    "movement_sim = compute_movement_similarity(dna_df, ARTIST_MOVEMENTS)\n",
    "\n",
    "print(\"Movement Color DNA Similarity:\")\n",
    "print(movement_sim.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize movement relationships\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "mask = np.triu(np.ones_like(movement_sim, dtype=bool), k=1)\n",
    "sns.heatmap(movement_sim, annot=True, fmt='.2f', cmap='RdYlBu_r',\n",
    "            center=0.5, square=True, linewidths=2, ax=ax,\n",
    "            cbar_kws={'shrink': 0.8, 'label': 'Color Similarity'},\n",
    "            annot_kws={'size': 11})\n",
    "\n",
    "ax.set_title('Art Movement Color DNA Similarity', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.yticks(rotation=0, fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influence network visualization\n",
    "def plot_influence_network(movement_sim, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Plot a network graph of movement influences based on color similarity.\n",
    "    \"\"\"\n",
    "    movements = list(movement_sim.index)\n",
    "    n = len(movements)\n",
    "    \n",
    "    # Position movements in a circle\n",
    "    angles = np.linspace(0, 2*np.pi, n, endpoint=False)\n",
    "    positions = {m: (np.cos(a), np.sin(a)) for m, a in zip(movements, angles)}\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Draw edges (connections above threshold)\n",
    "    for i, m1 in enumerate(movements):\n",
    "        for j, m2 in enumerate(movements):\n",
    "            if i < j:  # Upper triangle only\n",
    "                sim = movement_sim.loc[m1, m2]\n",
    "                if sim > threshold:\n",
    "                    x1, y1 = positions[m1]\n",
    "                    x2, y2 = positions[m2]\n",
    "                    # Line thickness based on similarity\n",
    "                    linewidth = (sim - threshold) / (1 - threshold) * 8 + 1\n",
    "                    alpha = 0.3 + 0.5 * (sim - threshold) / (1 - threshold)\n",
    "                    ax.plot([x1, x2], [y1, y2], 'b-', \n",
    "                           linewidth=linewidth, alpha=alpha, zorder=1)\n",
    "    \n",
    "    # Draw nodes\n",
    "    for m in movements:\n",
    "        x, y = positions[m]\n",
    "        color = MOVEMENT_COLORS.get(m, '#95a5a6')\n",
    "        ax.scatter(x, y, s=2000, c=color, edgecolors='white', \n",
    "                  linewidth=3, zorder=2)\n",
    "        ax.annotate(m, (x, y), ha='center', va='center', \n",
    "                   fontsize=9, fontweight='bold', color='white',\n",
    "                   zorder=3)\n",
    "    \n",
    "    ax.set_xlim(-1.5, 1.5)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Art Movement Color Connections\\n(Similarity > {threshold:.0%})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_influence_network(movement_sim, threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Deep Dive - Understanding Color DNA Features\n",
    "\n",
    "Let's examine what specific color characteristics distinguish different artists and movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key features for comparison\n",
    "key_features = [\n",
    "    'mean_saturation_mean', 'mean_brightness_mean', 'warm_ratio_mean',\n",
    "    'color_diversity_mean', 'harmony_score_mean', 'std_brightness_mean'\n",
    "]\n",
    "\n",
    "# Create feature comparison DataFrame\n",
    "feature_df = dna_df[key_features].copy()\n",
    "feature_df.columns = [c.replace('_mean', '').replace('mean_', '') for c in feature_df.columns]\n",
    "\n",
    "# Add movement column\n",
    "feature_df['movement'] = [get_movement(a) for a in feature_df.index]\n",
    "\n",
    "print(\"Key Color Features by Artist:\")\n",
    "print(feature_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature profiles for selected artists\n",
    "def plot_artist_radar(artists, feature_df, features):\n",
    "    \"\"\"\n",
    "    Create radar chart comparing artist color profiles.\n",
    "    \"\"\"\n",
    "    n_features = len(features)\n",
    "    angles = np.linspace(0, 2 * np.pi, n_features, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(artists)))\n",
    "    \n",
    "    for artist, color in zip(artists, colors):\n",
    "        # Find matching artist\n",
    "        matches = [a for a in feature_df.index if artist.lower() in a.lower()]\n",
    "        if not matches:\n",
    "            continue\n",
    "        artist_name = matches[0]\n",
    "        \n",
    "        values = feature_df.loc[artist_name, features].values.tolist()\n",
    "        \n",
    "        # Normalize to 0-1\n",
    "        min_vals = feature_df[features].min().values\n",
    "        max_vals = feature_df[features].max().values\n",
    "        values_norm = [(v - mi) / (ma - mi + 1e-6) for v, mi, ma in zip(values, min_vals, max_vals)]\n",
    "        values_norm += values_norm[:1]\n",
    "        \n",
    "        ax.plot(angles, values_norm, 'o-', linewidth=2, label=artist_name, color=color)\n",
    "        ax.fill(angles, values_norm, alpha=0.15, color=color)\n",
    "    \n",
    "    # Labels\n",
    "    feature_labels = [f.replace('_', '\\n').title() for f in features]\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(feature_labels, fontsize=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=10)\n",
    "    ax.set_title('Artist Color DNA Profiles', fontsize=14, fontweight='bold', y=1.08)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Compare Impressionists\n",
    "impressionists = ['Monet', 'Renoir', 'Degas', 'Pissarro']\n",
    "features = ['saturation', 'brightness', 'warm_ratio', 'color_diversity', 'harmony_score']\n",
    "plot_artist_radar(impressionists, feature_df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare across movements\n",
    "cross_movement = ['Monet', 'Van Gogh', 'Rembrandt', 'Picasso', 'Rothko']\n",
    "plot_artist_radar(cross_movement, feature_df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions by movement\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "features_to_plot = ['saturation', 'brightness', 'warm_ratio', \n",
    "                    'color_diversity', 'harmony_score', 'std_brightness']\n",
    "\n",
    "for ax, feature in zip(axes.flat, features_to_plot):\n",
    "    for movement in ['Impressionism', 'Post-Impressionism', 'Expressionism', 'Old Masters', 'Modern']:\n",
    "        subset = feature_df[feature_df['movement'] == movement]\n",
    "        if len(subset) > 0:\n",
    "            color = MOVEMENT_COLORS.get(movement, '#95a5a6')\n",
    "            ax.scatter([movement] * len(subset), subset[feature], \n",
    "                      c=color, s=100, alpha=0.7, edgecolors='white', linewidth=1)\n",
    "            ax.scatter([movement], [subset[feature].mean()], \n",
    "                      c=color, s=200, marker='D', edgecolors='black', linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel(feature.replace('_', ' ').title(), fontsize=11)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Color DNA Features by Movement\\n(Diamonds = Movement Mean)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Finding Unexpected Connections\n",
    "\n",
    "One of the most interesting applications: discovering unexpected similarities between artists from different eras or movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_surprising_similarities(similarity_df, artist_movements, top_n=10):\n",
    "    \"\"\"\n",
    "    Find pairs of artists from DIFFERENT movements with high color similarity.\n",
    "    These represent unexpected connections.\n",
    "    \"\"\"\n",
    "    surprising = []\n",
    "    \n",
    "    artists = list(similarity_df.index)\n",
    "    \n",
    "    for i, a1 in enumerate(artists):\n",
    "        for j, a2 in enumerate(artists):\n",
    "            if i >= j:  # Skip diagonal and lower triangle\n",
    "                continue\n",
    "            \n",
    "            m1 = get_movement(a1)\n",
    "            m2 = get_movement(a2)\n",
    "            \n",
    "            # Only consider different movements\n",
    "            if m1 != m2 and m1 != 'Other' and m2 != 'Other':\n",
    "                sim = similarity_df.loc[a1, a2]\n",
    "                surprising.append((a1, a2, m1, m2, sim))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    surprising.sort(key=lambda x: x[4], reverse=True)\n",
    "    \n",
    "    return surprising[:top_n]\n",
    "\n",
    "\n",
    "# Find surprising connections\n",
    "surprises = find_surprising_similarities(cosine_df, ARTIST_MOVEMENTS, top_n=10)\n",
    "\n",
    "print(\"SURPRISING COLOR CONNECTIONS\")\n",
    "print(\"Artists from different movements with similar Color DNA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (a1, a2, m1, m2, sim) in enumerate(surprises, 1):\n",
    "    print(f\"\\n{i}. {a1} ({m1}) ↔ {a2} ({m2})\")\n",
    "    print(f\"   Color similarity: {sim:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a surprising connection\n",
    "def compare_artist_palettes(artist1, artist2, n_works=3):\n",
    "    \"\"\"\n",
    "    Side-by-side comparison of two artists' typical palettes.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, n_works, figsize=(4*n_works, 4))\n",
    "    \n",
    "    for row, artist_name in enumerate([artist1, artist2]):\n",
    "        # Get artist works\n",
    "        artist_key = artist_name.lower().replace(' ', '-')\n",
    "        works = artist_analyzer.extract_artist_works(artist_key, limit=n_works)\n",
    "        \n",
    "        if not works:\n",
    "            # Try partial match\n",
    "            for name in artist_names:\n",
    "                if artist_name.lower().split()[-1] in name.lower():\n",
    "                    works = artist_analyzer.extract_artist_works(name, limit=n_works)\n",
    "                    if works:\n",
    "                        break\n",
    "        \n",
    "        for col, work in enumerate(works[:n_works]):\n",
    "            ax = axes[row, col]\n",
    "            palette = color_extractor.extract_dominant_colors(work['image'], n_colors=5)\n",
    "            \n",
    "            if palette:\n",
    "                for k, color in enumerate(palette):\n",
    "                    color_norm = tuple(c/255 for c in color)\n",
    "                    ax.add_patch(plt.Rectangle((k, 0), 1, 1, facecolor=color_norm, \n",
    "                                               edgecolor='white', lw=1))\n",
    "            \n",
    "            ax.set_xlim(0, 5)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            if col == 0:\n",
    "                ax.set_ylabel(artist_name, fontsize=12, fontweight='bold', \n",
    "                             rotation=0, ha='right', va='center', labelpad=10)\n",
    "    \n",
    "    plt.suptitle(f'Color Palette Comparison\\n{artist1} vs {artist2}', \n",
    "                fontsize=14, fontweight='bold', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Compare a surprising pair\n",
    "if surprises:\n",
    "    a1, a2, m1, m2, sim = surprises[0]\n",
    "    print(f\"\\nComparing: {a1} ({m1}) and {a2} ({m2})\")\n",
    "    print(f\"Color similarity: {sim:.1%}\\n\")\n",
    "    compare_artist_palettes(a1, a2, n_works=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Building an Interactive Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ArtistColorDNAExplorer:\n    \"\"\"\n    Interactive explorer for artist Color DNA.\n    \"\"\"\n    \n    def __init__(self, dna_df, similarity_df, embeddings_2d, artist_list):\n        self.dna_df = dna_df\n        self.similarity_df = similarity_df\n        self.embeddings_2d = embeddings_2d\n        self.artist_list = artist_list\n    \n    def search(self, query):\n        \"\"\"Search for artists by name.\"\"\"\n        matches = [a for a in self.artist_list if query.lower() in a.lower()]\n        return matches\n    \n    def get_profile(self, artist_name):\n        \"\"\"Get Color DNA profile for an artist.\"\"\"\n        matches = self.search(artist_name)\n        if not matches:\n            return None\n        \n        artist = matches[0]\n        profile = self.dna_df.loc[artist]\n        \n        # Extract key features\n        key_info = {\n            'Saturation': profile.get('mean_saturation_mean', 0),\n            'Brightness': profile.get('mean_brightness_mean', 0),\n            'Warm Colors': profile.get('warm_ratio_mean', 0) * 100,\n            'Cool Colors': profile.get('cool_ratio_mean', 0) * 100,\n            'Color Diversity': profile.get('color_diversity_mean', 0),\n            'Harmony Score': profile.get('harmony_score_mean', 0),\n        }\n        \n        return artist, key_info\n    \n    def recommend(self, artist_name, n=5):\n        \"\"\"Get similar artist recommendations.\"\"\"\n        return find_similar_artists(artist_name, self.similarity_df, n)\n    \n    def compare(self, artist1, artist2):\n        \"\"\"Compare two artists' Color DNA.\"\"\"\n        p1 = self.get_profile(artist1)\n        p2 = self.get_profile(artist2)\n        \n        if not p1 or not p2:\n            return None\n        \n        # Get similarity\n        sim = self.similarity_df.loc[p1[0], p2[0]]\n        \n        return {\n            'artist1': p1,\n            'artist2': p2,\n            'similarity': sim\n        }\n    \n    def display_profile(self, artist_name):\n        \"\"\"Display a formatted artist profile.\"\"\"\n        result = self.get_profile(artist_name)\n        if not result:\n            print(f\"Artist '{artist_name}' not found.\")\n            return\n        \n        artist, info = result\n        movement = get_movement(artist)\n        \n        print(f\"\\n{'='*50}\")\n        print(f\"{artist}\")\n        print(f\"   Movement: {movement}\")\n        print(f\"{'='*50}\")\n        print(\"\\nColor DNA Profile:\")\n        for key, value in info.items():\n            if 'Color' in key:\n                print(f\"  {key}: {value:.1f}%\")\n            else:\n                print(f\"  {key}: {value:.2f}\")\n        \n        # Get recommendations\n        print(\"\\nSimilar Artists:\")\n        recs = self.recommend(artist_name, n=3)\n        for rec_artist, score in recs:\n            rec_movement = get_movement(rec_artist)\n            print(f\"  - {rec_artist} ({rec_movement}) - {score:.0%} similar\")\n\n\n# Create explorer\nexplorer = ArtistColorDNAExplorer(dna_df, cosine_df, X_tsne, artist_list)\n\n# Demo\nexplorer.display_profile('Monet')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore more artists\n",
    "explorer.display_profile('Van Gogh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explorer.display_profile('Rembrandt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "### What We Built\n",
    "\n",
    "1. **Color DNA Fingerprints**: 50+ dimensional vectors capturing each artist's color signature\n",
    "2. **Similarity Metrics**: Cosine similarity for comparing artistic styles\n",
    "3. **Visualizations**: t-SNE/UMAP projections, dendrograms, heatmaps\n",
    "4. **Recommendation System**: \"If you like X, try Y\" based on color similarity\n",
    "5. **Influence Analysis**: Movement-level color relationships\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Movements cluster by color**: Impressionists, Expressionists, Old Masters form distinct groups\n",
    "- **Unexpected connections**: Some artists from different eras share color DNA\n",
    "- **Distinguishing features**: Saturation, brightness, and temperature are key differentiators\n",
    "- **Color harmony varies**: Some movements emphasize complementary colors, others analogous\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Art Education**: Understanding stylistic relationships\n",
    "- **Museum Curation**: Grouping artworks by visual similarity\n",
    "- **Artist Discovery**: Recommending new artists to art enthusiasts\n",
    "- **Art History Research**: Quantifying artistic influences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Exercise 1: Add more artists to the analysis\n",
    "# Expand ARTISTS_TO_ANALYZE with your favorite artists\n",
    "\n",
    "# Exercise 2: Create genre-based Color DNA\n",
    "# Instead of artists, analyze genres (portraits, landscapes, etc.)\n",
    "\n",
    "# Exercise 3: Time-based analysis\n",
    "# How did an artist's Color DNA change over their career?\n",
    "\n",
    "# Exercise 4: Weighted recommendations\n",
    "# Allow users to specify which features matter most to them\n",
    "\n",
    "# Exercise 5: Cross-cultural analysis\n",
    "# Compare Eastern vs Western art color signatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you've created a complete **Artist Color DNA system**:\n",
    "\n",
    "1. **Extracted** rich color fingerprints from thousands of artworks\n",
    "2. **Visualized** the landscape of artistic styles in embedding space\n",
    "3. **Built** a recommendation system for discovering similar artists\n",
    "4. **Analyzed** artistic influences through color similarity\n",
    "5. **Discovered** unexpected connections between artists across eras\n",
    "\n",
    "**Key Insight**: Color alone encodes tremendous information about artistic style. The Color DNA we've created captures not just what colors artists use, but *how* they use them—their temperature preferences, contrast patterns, harmony choices, and diversity. This numerical fingerprint enables computational exploration of art history in ways that complement traditional scholarship.\n",
    "\n",
    "This is the power of treating artistic style as data: we can quantify, compare, and discover patterns that might take human experts years to uncover!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}